{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Cp67lDbGNw"
   },
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7237,
     "status": "ok",
     "timestamp": 1608736189510,
     "user": {
      "displayName": "Tang Tsai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64",
      "userId": "14641643808163269187"
     },
     "user_tz": -480
    },
    "id": "IhIDRaN5bGNw"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['font.sans-serif'] = ['FangSong'] # 指定默认字体\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIQy13slLw-G"
   },
   "source": [
    "### ANN without 1h/h average SBP & DBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82091,
     "status": "ok",
     "timestamp": 1608740131358,
     "user": {
      "displayName": "Tang Tsai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64",
      "userId": "14641643808163269187"
     },
     "user_tz": -480
    },
    "id": "_QF1-zw62vmE",
    "outputId": "e7397648-7758-4208-d6f6-1878febece83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8354919535262382 0.83365847640665 tensor(0.7662) tensor(0.7657) tensor(0.7781) tensor(0.7762) tensor(0.7617) tensor(0.7622) tensor(0.8259) tensor(0.8255)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_range_pro = pd.read_csv('/content/drive/My Drive/hypertension test/Nocturnal_hypertension by C/data_10factors_gbk_dayBP_201222.csv', encoding = 'gbk', index_col = 0)\n",
    "def preprocess(data0):\n",
    "    data = data0.copy()\n",
    "    X_col = [col for col in data.columns if col != 'nocturnal_hypertension']\n",
    "    dummy_col = [col for col in X_col if len(data[col].unique()) < 5]\n",
    "    data[dummy_col] = data[dummy_col].astype('int64')\n",
    "    float_col = [col for col in X_col if col not in dummy_col]\n",
    "    # standard\n",
    "    m,s = data[float_col].mean(), data[float_col].std()\n",
    "    for col in float_col:\n",
    "        data[col] = (data[col] - data[col].mean()) / (data[col].std())\n",
    "    temp = pd.DataFrame()\n",
    "    for col in dummy_col:\n",
    "        temp = pd.concat([temp, pd.get_dummies(data[col], prefix = col, prefix_sep = '_', drop_first = True)], axis = 1)\n",
    "\n",
    "    temp = pd.concat([data[float_col], temp, data['nocturnal_hypertension']], axis = 1)\n",
    "    temp.index = pd.Index(range(len(temp)))\n",
    "    return temp, m, s, float_col, dummy_col, X_col, 'nocturnal_hypertension'\n",
    "\n",
    "data, m, s, float_col, dummy_col, X_col, y_col = preprocess(data_range_pro)\n",
    "data['nocturnal_hypertension'] = data['nocturnal_hypertension'].astype('int')#bool转换成int\n",
    "\n",
    "R = 115306\n",
    "\n",
    "temp = ['Clinic SBP,mmHg','eGFR,mL/ (min·1.73 m2)','BUN,mmol/L','Clinic DBP,mmHg'\n",
    "             ,'nRAAS drugs intake_1', 'Hypertension_1','Age,y'] + [y_col]\n",
    "\n",
    "data_tensor = torch.from_numpy(data[temp].values).float()\n",
    "\n",
    "X = data_tensor[:,:-1]\n",
    "y = data_tensor[:,-1].resize(3103,1)\n",
    "\n",
    "kf = KFold(10,shuffle = True, random_state = R)\n",
    "\n",
    "result = []\n",
    "for train_idx, test_idx in kf.split(range(X.shape[0])):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    model = torch.nn.Sequential(torch.nn.Linear(7,15),\n",
    "                            torch.nn.Sigmoid(), \n",
    "                            torch.nn.Linear(15,1),\n",
    "                            torch.nn.Sigmoid())\n",
    "    loss = torch.nn.MSELoss(reduce = False)\n",
    "    optimizer=torch.optim.SGD(model.parameters(),lr=0.05,weight_decay=0.001)\n",
    "    sw = y_train.clone()\n",
    "\n",
    "    sw[sw == 1] = y_train.shape[0]/(2*y_train.float().sum())   \n",
    "    \n",
    "    sw[sw == 0] = y_train.shape[0]/(2*(y_train==0).float().sum())\n",
    "    \n",
    "    for epoch in range(10000):\n",
    "        optimizer.zero_grad()  \n",
    "        out = model(X_train)  \n",
    "        loss1 = (sw * loss(out, y_train)).sum()/sw.sum()  \n",
    "        loss1.backward()    \n",
    "        optimizer.step()    \n",
    "    out_train = model(X_train) \n",
    "    out_test = model(X_test)\n",
    "\n",
    "    acc_train = ((out_train>0.5).float()==y_train).float().mean()\n",
    "    acc_test = ((out_test>0.5).float()==y_test).float().mean()\n",
    "    sen_train =  ((out_train >0.5).float() == y_train)[y_train == 1].float().mean()\n",
    "    sen_test =  ((out_test >0.5).float() == y_test)[y_test == 1].float().mean()\n",
    "    spe_train =  ((out_train >0.5).float() == y_train)[y_train == 0].float().mean()\n",
    "    spe_test =  ((out_test >0.5).float() == y_test)[y_test == 0].float().mean()\n",
    "\n",
    "    train_fpr, train_tpr, train_thresholds = roc_curve(y_train.detach().numpy(), out_train.detach().numpy())\n",
    "    test_fpr, test_tpr, test_thresholds = roc_curve(y_test.detach().numpy(), out_test.detach().numpy())\n",
    "    train_auc = auc(train_fpr, train_tpr)\n",
    "    test_auc = auc(test_fpr, test_tpr)\n",
    "\n",
    "    train_pre = ((out_train>0.5)&(y_train == 1)).sum().numpy()/(out_train >0.5).sum().numpy()\n",
    "    test_pre = ((out_test>0.5)&(y_test == 1)).sum().numpy()/(out_test>0.5).sum().numpy()\n",
    "\n",
    "    F1_train = (2*train_pre*sen_train)/(train_pre + sen_train)\n",
    "    F1_test = (2*test_pre*sen_test)/(test_pre + sen_test)\n",
    "\n",
    "    result.append({'train':{'acc':acc_train, 'sensitivity':sen_train, 'specivity':spe_train,'auc':train_auc, 'F1':F1_train},\n",
    "                  'test':{'acc':acc_test, 'sensitivity':sen_test, 'specivity':spe_test,'auc':test_auc, 'F1':F1_test}})\n",
    "acc_train, acc_test, sen_train, sen_test, spe_train, spe_test, auc_train, auc_test,F1_train, F1_test = 0,0,0,0,0,0,0,0,0,0\n",
    "for temp in result:\n",
    "    a =  temp['train']\n",
    "    b = temp ['test']\n",
    "    acc_train += 0.1*a['acc']\n",
    "    acc_test += 0.1*b['acc']\n",
    "    sen_train += 0.1*a['sensitivity']\n",
    "    sen_test += 0.1*b['sensitivity']\n",
    "    spe_train += 0.1*a['specivity']\n",
    "    spe_test += 0.1*b['specivity']\n",
    "    auc_train += 0.1*a['auc']\n",
    "    auc_test += 0.1*b['auc']\n",
    "    F1_train += 0.1*a['F1']\n",
    "    F1_test += 0.1 * b['F1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdho8pYpMgUz"
   },
   "source": [
    "### ANN with 1h/h average SBP & DBP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2287,
     "status": "ok",
     "timestamp": 1608736975263,
     "user": {
      "displayName": "Tang Tsai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64",
      "userId": "14641643808163269187"
     },
     "user_tz": -480
    },
    "id": "iz5ooPC5Lo_w"
   },
   "outputs": [],
   "source": [
    "data_range_pro = pd.read_csv('/content/drive/My Drive/hypertension test/Nocturnal_hypertension by C/data_10factors_gbk_dayBP_201222.csv', encoding = 'gbk', index_col = 0)\n",
    "X_daytime = ['8-9SBP',\n",
    " '8-9DBP',\n",
    " '9-10SBP',\n",
    " '9-10DBP',\n",
    " '10-11SBP',\n",
    " '10-11DBP',\n",
    " '11-12SBP',\n",
    " '11-12DBP',\n",
    " '3-4SBP',\n",
    " '3-4DBP',\n",
    " '4-5SBP',\n",
    " '4-5DBP',\n",
    " '5-6SBP',\n",
    " '5-6DBP',\n",
    "         \n",
    "  '8-10SBP',\n",
    "  '8-10DBP',\n",
    "  '9-11SBP',\n",
    "  '9-11DBP',\n",
    "  '10-12SBP',\n",
    "  '10-12DBP',\n",
    "  '3-5SBP',\n",
    "  '3-5DBP',\n",
    "  '4-6SBP',\n",
    "  '4-6DBP',\n",
    "]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1519,
     "status": "ok",
     "timestamp": 1608737031815,
     "user": {
      "displayName": "Tang Tsai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64",
      "userId": "14641643808163269187"
     },
     "user_tz": -480
    },
    "id": "dcgnskyssxHT"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame( columns=('8-9SBP',\n",
    "#  '8-9DBP',\n",
    " '9-10SBP',\n",
    "#  '9-10DBP',\n",
    " '10-11SBP',\n",
    "#  '10-11DBP',\n",
    " '11-12SBP',\n",
    "#  '11-12DBP',\n",
    " '3-4SBP',\n",
    "#  '3-4DBP',\n",
    " '4-5SBP',\n",
    "#  '4-5DBP',\n",
    " '5-6SBP',\n",
    "#  '5-6DBP',\n",
    "         \n",
    "  '8-10SBP',\n",
    "#  '8-10DBP',\n",
    "  '9-11SBP',\n",
    "#  '9-11DBP',\n",
    "  '10-12SBP',\n",
    "#  '10-12DBP',\n",
    "  '3-5SBP',\n",
    "#  '3-5DBP',\n",
    "  '4-6SBP',\n",
    "#  '4-6DBP',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 997060,
     "status": "ok",
     "timestamp": 1608739879853,
     "user": {
      "displayName": "Tang Tsai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64",
      "userId": "14641643808163269187"
     },
     "user_tz": -480
    },
    "id": "t92LWF_zbGN1",
    "outputId": "cf9b5039-8b07-41e2-e28c-19962e38feb9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8-9SBP 8-9DBP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8718319730686783 0.8705224698895966 tensor(0.7929) tensor(0.7915) tensor(0.8043) tensor(0.8025) tensor(0.7886) tensor(0.7880) tensor(0.8472) tensor(0.8460)\n",
      "9-10SBP 9-10DBP\n",
      "0.8705949498809304 0.8701900861933819 tensor(0.7912) tensor(0.7915) tensor(0.8014) tensor(0.8006) tensor(0.7874) tensor(0.7885) tensor(0.8460) tensor(0.8462)\n",
      "10-11SBP 10-11DBP\n",
      "0.8728976370246769 0.8713112248613948 tensor(0.7873) tensor(0.7850) tensor(0.7956) tensor(0.7893) tensor(0.7842) tensor(0.7842) tensor(0.8430) tensor(0.8414)\n",
      "11-12SBP 11-12DBP\n",
      "0.8723007412106318 0.8701991786880264 tensor(0.7931) tensor(0.7915) tensor(0.7961) tensor(0.7936) tensor(0.7920) tensor(0.7911) tensor(0.8480) tensor(0.8466)\n",
      "3-4SBP 3-4DBP\n",
      "0.8789324543514843 0.8775116259703728 tensor(0.7955) tensor(0.7950) tensor(0.8111) tensor(0.8098) tensor(0.7896) tensor(0.7899) tensor(0.8490) tensor(0.8487)\n",
      "4-5SBP 4-5DBP\n",
      "0.8821795284020374 0.8800920318280515 tensor(0.7938) tensor(0.7915) tensor(0.8116) tensor(0.8071) tensor(0.7872) tensor(0.7858) tensor(0.8476) tensor(0.8458)\n",
      "5-6SBP 5-6DBP\n",
      "0.8819280642072577 0.8804073684703739 tensor(0.7968) tensor(0.7925) tensor(0.8031) tensor(0.7990) tensor(0.7944) tensor(0.7903) tensor(0.8506) tensor(0.8472)\n",
      "8-10SBP 8-10DBP\n",
      "0.8812135713020417 0.8800951611044878 tensor(0.8023) tensor(0.8002) tensor(0.8185) tensor(0.8189) tensor(0.7963) tensor(0.7939) tensor(0.8544) tensor(0.8525)\n",
      "9-11SBP 9-11DBP\n",
      "0.8794780961210722 0.878358993405678 tensor(0.7977) tensor(0.7960) tensor(0.8107) tensor(0.8105) tensor(0.7929) tensor(0.7911) tensor(0.8510) tensor(0.8493)\n",
      "10-12SBP 10-12DBP\n",
      "0.8806535195031493 0.8792799784580442 tensor(0.7999) tensor(0.7999) tensor(0.8103) tensor(0.8117) tensor(0.7960) tensor(0.7961) tensor(0.8528) tensor(0.8527)\n",
      "3-5SBP 3-5DBP\n",
      "0.8895567144087881 0.8876557766059896 tensor(0.8054) tensor(0.8041) tensor(0.8322) tensor(0.8283) tensor(0.7954) tensor(0.7952) tensor(0.8562) tensor(0.8552)\n",
      "4-6SBP 4-6DBP\n",
      "0.8920135264457933 0.8901808856512364 tensor(0.8008) tensor(0.7996) tensor(0.8151) tensor(0.8115) tensor(0.7954) tensor(0.7951) tensor(0.8533) tensor(0.8523)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_range_pro = pd.read_csv('/content/drive/My Drive/hypertension test/Nocturnal_hypertension by C/data_10factors_gbk_dayBP_201222.csv', encoding = 'gbk', index_col = 0)\n",
    "def preprocess(data0):\n",
    "    data = data0.copy()\n",
    "    X_col = [col for col in data.columns if col != 'nocturnal_hypertension']\n",
    "    dummy_col = [col for col in X_col if len(data[col].unique()) < 5]\n",
    "    data[dummy_col] = data[dummy_col].astype('int64')\n",
    "    float_col = [col for col in X_col if col not in dummy_col]\n",
    "    # standard\n",
    "    m,s = data[float_col].mean(), data[float_col].std()\n",
    "    for col in float_col:\n",
    "        data[col] = (data[col] - data[col].mean()) / (data[col].std())\n",
    "    temp = pd.DataFrame()\n",
    "    for col in dummy_col:\n",
    "        temp = pd.concat([temp, pd.get_dummies(data[col], prefix = col, prefix_sep = '_', drop_first = True)], axis = 1)\n",
    "\n",
    "    temp = pd.concat([data[float_col], temp, data['nocturnal_hypertension']], axis = 1)\n",
    "    temp.index = pd.Index(range(len(temp)))\n",
    "    return temp, m, s, float_col, dummy_col, X_col, 'nocturnal_hypertension'\n",
    "\n",
    "data, m, s, float_col, dummy_col, X_col, y_col = preprocess(data_range_pro)\n",
    "data['nocturnal_hypertension'] = data['nocturnal_hypertension'].astype('int')#bool转换成int\n",
    "\n",
    "R = 115306\n",
    "\n",
    "temp = ['Clinic SBP,mmHg','eGFR,mL/ (min·1.73 m2)','BUN,mmol/L','Clinic DBP,mmHg'\n",
    "             ,'nRAAS drugs intake_1', 'Hypertension_1','Age,y'] + [y_col]\n",
    "\n",
    "for j in range(int(len(X_daytime)/2)):\n",
    "    i = j*2\n",
    "    temp = ['Clinic SBP,mmHg','eGFR,mL/ (min·1.73 m2)','BUN,mmol/L','Clinic DBP,mmHg'\n",
    "             ,'nRAAS drugs intake_1', 'Hypertension_1','Age,y',\n",
    "      X_daytime[i],X_daytime[i+1]\n",
    "    ] + [y_col]\n",
    "    data_tensor = torch.from_numpy(data[temp].values).float()\n",
    "\n",
    "    X = data_tensor[:,:-1]\n",
    "    y = data_tensor[:,-1].resize(3103,1)\n",
    "\n",
    "    kf = KFold(10,shuffle = True, random_state = R)\n",
    "\n",
    "    result = []\n",
    "    for train_idx, test_idx in kf.split(range(X.shape[0])):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        model = torch.nn.Sequential(torch.nn.Linear(9,15),\n",
    "                                torch.nn.Sigmoid(), \n",
    "                                torch.nn.Linear(15,1),\n",
    "                                torch.nn.Sigmoid())\n",
    "        loss = torch.nn.MSELoss(reduce = False)\n",
    "        optimizer=torch.optim.SGD(model.parameters(),lr=0.05,weight_decay=0.001)\n",
    "        sw = y_train.clone()\n",
    "\n",
    "        sw[sw == 1] = y_train.shape[0]/(2*y_train.float().sum())   \n",
    "        \n",
    "        sw[sw == 0] = y_train.shape[0]/(2*(y_train==0).float().sum())\n",
    "        \n",
    "        for epoch in range(10000):\n",
    "            optimizer.zero_grad()  \n",
    "            out = model(X_train)  \n",
    "            loss1 = (sw * loss(out, y_train)).sum()/sw.sum()  \n",
    "            loss1.backward()    \n",
    "            optimizer.step()    \n",
    "        out_train = model(X_train) \n",
    "        out_test = model(X_test)\n",
    "\n",
    "        acc_train = ((out_train>0.5).float()==y_train).float().mean()\n",
    "        acc_test = ((out_test>0.5).float()==y_test).float().mean()\n",
    "        sen_train =  ((out_train >0.5).float() == y_train)[y_train == 1].float().mean()\n",
    "        sen_test =  ((out_test >0.5).float() == y_test)[y_test == 1].float().mean()\n",
    "        spe_train =  ((out_train >0.5).float() == y_train)[y_train == 0].float().mean()\n",
    "        spe_test =  ((out_test >0.5).float() == y_test)[y_test == 0].float().mean()\n",
    "\n",
    "        train_fpr, train_tpr, train_thresholds = roc_curve(y_train.detach().numpy(), out_train.detach().numpy())\n",
    "        test_fpr, test_tpr, test_thresholds = roc_curve(y_test.detach().numpy(), out_test.detach().numpy())\n",
    "        train_auc = auc(train_fpr, train_tpr)\n",
    "        test_auc = auc(test_fpr, test_tpr)\n",
    "\n",
    "        train_pre = ((out_train>0.5)&(y_train == 1)).sum().numpy()/(out_train >0.5).sum().numpy()\n",
    "        test_pre = ((out_test>0.5)&(y_test == 1)).sum().numpy()/(out_test>0.5).sum().numpy()\n",
    "\n",
    "        F1_train = (2*train_pre*sen_train)/(train_pre + sen_train)\n",
    "        F1_test = (2*test_pre*sen_test)/(test_pre + sen_test)\n",
    "\n",
    "        result.append({'train':{'acc':acc_train, 'sensitivity':sen_train, 'specivity':spe_train,'auc':train_auc, 'F1':F1_train},\n",
    "                      'test':{'acc':acc_test, 'sensitivity':sen_test, 'specivity':spe_test,'auc':test_auc, 'F1':F1_test}})\n",
    "    acc_train, acc_test, sen_train, sen_test, spe_train, spe_test, auc_train, auc_test,F1_train, F1_test = 0,0,0,0,0,0,0,0,0,0\n",
    "    for temp in result:\n",
    "        a =  temp['train']\n",
    "        b = temp ['test']\n",
    "        acc_train += 0.1*a['acc']\n",
    "        acc_test += 0.1*b['acc']\n",
    "        sen_train += 0.1*a['sensitivity']\n",
    "        sen_test += 0.1*b['sensitivity']\n",
    "        spe_train += 0.1*a['specivity']\n",
    "        spe_test += 0.1*b['specivity']\n",
    "        auc_train += 0.1*a['auc']\n",
    "        auc_test += 0.1*b['auc']\n",
    "        F1_train += 0.1*a['F1']\n",
    "        F1_test += 0.1 * b['F1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpgL18h9KRJM"
   },
   "source": [
    "### **Test with extra data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 74921,
     "status": "ok",
     "timestamp": 1608740131360,
     "user": {
      "displayName": "Tang Tsai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64",
      "userId": "14641643808163269187"
     },
     "user_tz": -480
    },
    "id": "hbXTyRRJJo01"
   },
   "outputs": [],
   "source": [
    "data_range_pro = pd.read_csv('/content/drive/My Drive/hypertension test/Nocturnal_hypertension by C/data_10factors_gbk_dayBP_201222.csv', encoding = 'gbk', index_col = 0)\n",
    "data_ex_valid = pd.read_csv('/content/drive/My Drive/hypertension test/Nocturnal_hypertension by C/data_ex_valid.csv', encoding = 'gbk', index_col = 0)\n",
    "data_ex_valid.rename(columns = {'姓名':'Name','编号':'No.','性别（1男2女）':'Male','年龄':'Age,y','BMI':'BMI,kg/m2','吸烟0否1是':'Smoker'\n",
    "                       ,'饮酒':'Alcohol intake','糖尿病':'Diabetes mellitus','高血压':'Hypertension','高脂血症':'Hyperlipidemia'\n",
    "                       ,'高血压家族史':'Hypertension family history','CVD既往史':'CVD history','是否用降压药':'Antihypertension drugs'\n",
    "                       ,'RAAS药':'RAAS drugs intake','nRAAS药':'nRAAS drugs intake','24H尿蛋白mg':'Proteinuria,mg/24h'\n",
    "                       ,'HGB':'Hemoglobin,g/L','尿素氮':'BUN,mmol/L','肌酐':'Scr,mmol/L','尿酸':'Uric acid,mmol/L'\n",
    "                       ,'空腹血糖':'FBG,mmol/L','甘油三酯':'Triglyceride,mmol/L','胆固醇':'Cholesterol,mmol/L','高密度脂蛋白':'HDL-C,mmol/L'\n",
    "                       ,'低密度脂蛋白':'LDL-C,mmol/L','白蛋白':'Serum albumin,g/L','Na':'Serum sodium,mmol/L','CA':'Serum calcium,mmol/L'\n",
    "                       ,'P':'Serum phosphate,mmol/L','B2-微球蛋白':'β2-MG,ug/mL','甲状旁腺素（pg/ml）':'iPTH,pg/mL'\n",
    "                       ,'同型半胱氨酸':'Homocysteine,umol/L','GFR-EPI':'eGFR,mL/ (min·1.73 m2)'\n",
    "                       ,'诊室SBP':'Clinic SBP,mmHg','诊室DBP':'Clinic DBP,mmHg'},inplace = True)\n",
    "data_ex_valid = data_ex_valid[['Clinic SBP,mmHg','eGFR,mL/ (min·1.73 m2)','BUN,mmol/L','Clinic DBP,mmHg'\n",
    "             ,'nRAAS drugs intake', 'Hypertension'\n",
    "             ,'Age,y'\n",
    "             ,'10-11DBP', '10-11SBP', '10-12DBP', '10-12SBP', '11-12DBP', '11-12SBP'\n",
    "             ,'3-4DBP', '3-4SBP', '3-5DBP', '3-5SBP', '4-5DBP', '4-5SBP', '4-6DBP','4-6SBP'\n",
    "             , '5-6DBP', '5-6SBP', '8-10DBP', '8-10SBP'\n",
    "             , '8-9DBP', '8-9SBP', '9-10DBP', '9-10SBP', '9-11DBP','9-11SBP','nocturnal_hypertension']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 74430,
     "status": "ok",
     "timestamp": 1608740131362,
     "user": {
      "displayName": "Tang Tsai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64",
      "userId": "14641643808163269187"
     },
     "user_tz": -480
    },
    "id": "9g33hotLJxZK"
   },
   "outputs": [],
   "source": [
    "X_daytime = ['8-9SBP',\n",
    " '8-9DBP',\n",
    " '9-10SBP',\n",
    " '9-10DBP',\n",
    " '10-11SBP',\n",
    " '10-11DBP',\n",
    " '11-12SBP',\n",
    " '11-12DBP',\n",
    " '3-4SBP',\n",
    " '3-4DBP',\n",
    " '4-5SBP',\n",
    " '4-5DBP',\n",
    " '5-6SBP',\n",
    " '5-6DBP',\n",
    "         \n",
    "  '8-10SBP',\n",
    "  '8-10DBP',\n",
    "  '9-11SBP',\n",
    "  '9-11DBP',\n",
    "  '10-12SBP',\n",
    "  '10-12DBP',\n",
    "  '3-5SBP',\n",
    "  '3-5DBP',\n",
    "  '4-6SBP',\n",
    "  '4-6DBP',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1065012,
     "status": "ok",
     "timestamp": 1608741122977,
     "user": {
      "displayName": "Tang Tsai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64",
      "userId": "14641643808163269187"
     },
     "user_tz": -480
    },
    "id": "M9SfBH7BFhwm",
    "outputId": "b08fb70f-f872-41eb-d426-69c4b1c3eb48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8-9SBP 8-9DBP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8717950925385561 0.8704791523263262 tensor(0.7926) tensor(0.7918) tensor(0.8035) tensor(0.8049) tensor(0.7886) tensor(0.7876) tensor(0.8471) tensor(0.8461)\n",
      "229\n",
      "tensor(0.7642) tensor(0.7568) tensor(0.7778) 0.8293293293293293 tensor(0.8229)\n",
      "9-10SBP 9-10DBP\n",
      "0.8704921755126124 0.8699243754132548 tensor(0.7915) tensor(0.7908) tensor(0.8018) tensor(0.8018) tensor(0.7877) tensor(0.7872) tensor(0.8462) tensor(0.8456)\n",
      "229\n",
      "tensor(0.7555) tensor(0.7500) tensor(0.7654) 0.8303303303303304 tensor(0.8192)\n",
      "10-11SBP 10-11DBP\n",
      "0.872925838797769 0.8709792235817952 tensor(0.7872) tensor(0.7863) tensor(0.7952) tensor(0.7918) tensor(0.7843) tensor(0.7850) tensor(0.8430) tensor(0.8424)\n",
      "229\n",
      "tensor(0.7467) tensor(0.7432) tensor(0.7531) 0.8308308308308308 tensor(0.8145)\n",
      "11-12SBP 11-12DBP\n",
      "0.8725670257732832 0.870135136869445 tensor(0.7924) tensor(0.7915) tensor(0.7953) tensor(0.7926) tensor(0.7912) tensor(0.7916) tensor(0.8473) tensor(0.8467)\n",
      "229\n",
      "tensor(0.7948) tensor(0.7905) tensor(0.8025) 0.8502669336002668 tensor(0.8334)\n",
      "3-4SBP 3-4DBP\n",
      "0.8789495866098236 0.877240961103958 tensor(0.7952) tensor(0.7947) tensor(0.8111) tensor(0.8110) tensor(0.7892) tensor(0.7890) tensor(0.8488) tensor(0.8484)\n",
      "229\n",
      "tensor(0.7424) tensor(0.7297) tensor(0.7654) 0.844260927594261 tensor(0.8185)\n",
      "4-5SBP 4-5DBP\n",
      "0.8820962891033326 0.8803212195082908 tensor(0.7941) tensor(0.7918) tensor(0.8127) tensor(0.8093) tensor(0.7872) tensor(0.7854) tensor(0.8478) tensor(0.8459)\n",
      "229\n",
      "tensor(0.7598) tensor(0.7365) tensor(0.8025) 0.8419252585919254 tensor(0.8264)\n",
      "5-6SBP 5-6DBP\n",
      "0.8818762732421008 0.8800202531405116 tensor(0.7964) tensor(0.7912) tensor(0.8043) tensor(0.7990) tensor(0.7935) tensor(0.7885) tensor(0.8503) tensor(0.8461)\n",
      "229\n",
      "tensor(0.7380) tensor(0.7162) tensor(0.7778) 0.8309142475809143 tensor(0.8203)\n",
      "8-10SBP 8-10DBP\n",
      "0.8811398587711836 0.880173843731791 tensor(0.8024) tensor(0.8018) tensor(0.8193) tensor(0.8200) tensor(0.7961) tensor(0.7957) tensor(0.8544) tensor(0.8538)\n",
      "229\n",
      "tensor(0.7686) tensor(0.7568) tensor(0.7901) 0.8458458458458459 tensor(0.8304)\n",
      "9-11SBP 9-11DBP\n",
      "0.8794659417164387 0.8783597158873088 tensor(0.7969) tensor(0.7944) tensor(0.8105) tensor(0.8116) tensor(0.7918) tensor(0.7885) tensor(0.8503) tensor(0.8479)\n",
      "229\n",
      "tensor(0.7555) tensor(0.7432) tensor(0.7778) 0.8425091758425091 tensor(0.8224)\n",
      "10-12SBP 10-12DBP\n",
      "0.8805276571470877 0.8796203461813468 tensor(0.7999) tensor(0.7986) tensor(0.8110) tensor(0.8105) tensor(0.7957) tensor(0.7948) tensor(0.8528) tensor(0.8517)\n",
      "229\n",
      "tensor(0.7904) tensor(0.7973) tensor(0.7778) 0.8531031031031031 tensor(0.8296)\n",
      "3-5SBP 3-5DBP\n",
      "0.8896110673767831 0.8876269674480607 tensor(0.8048) tensor(0.8025) tensor(0.8310) tensor(0.8272) tensor(0.7951) tensor(0.7934) tensor(0.8558) tensor(0.8539)\n",
      "229\n",
      "tensor(0.7511) tensor(0.7230) tensor(0.8025) 0.8599432766099432 tensor(0.8299)\n",
      "4-6SBP 4-6DBP\n",
      "0.892030879725213 0.8900963329302032 tensor(0.8006) tensor(0.7989) tensor(0.8160) tensor(0.8115) tensor(0.7949) tensor(0.7942) tensor(0.8531) tensor(0.8518)\n",
      "229\n",
      "tensor(0.7642) tensor(0.7500) tensor(0.7901) 0.845845845845846 tensor(0.8291)\n"
     ]
    }
   ],
   "source": [
    "data, m, s, float_col, dummy_col, X_col, y_col = preprocess(data_range_pro)\n",
    "data['nocturnal_hypertension'] = data['nocturnal_hypertension'].astype('int')#bool转换成int\n",
    "data_ex, m_ex, s_ex, float_col_ex, dummy_col_ex, X_col_ex, y_col_ex = preprocess(data_ex_valid)\n",
    "data_ex['nocturnal_hypertension'] = data_ex['nocturnal_hypertension'].astype('int')#bool转换成int                                                                                 \n",
    "\n",
    "for j in range(int(len(X_daytime)/2)):\n",
    "    i = j*2\n",
    "    temp = ['Clinic SBP,mmHg','eGFR,mL/ (min·1.73 m2)','BUN,mmol/L','Clinic DBP,mmHg'\n",
    "             ,'nRAAS drugs intake_1', 'Hypertension_1','Age,y',\n",
    "      X_daytime[i],X_daytime[i+1]\n",
    "    ] + [y_col]\n",
    "\n",
    "    data_tensor = torch.from_numpy(data[temp].values).float()\n",
    "    data_tensor_ex = torch.from_numpy(data_ex[temp].values).float()\n",
    "\n",
    "    X = data_tensor[:,:-1]\n",
    "    y = data_tensor[:,-1].resize(3103,1)\n",
    "\n",
    "    X_ex = data_tensor_ex[:,:-1]\n",
    "    y_ex = data_tensor_ex[:,-1].resize(229,1)\n",
    "\n",
    "    kf = KFold(10,shuffle = True, random_state = 115306)\n",
    "\n",
    "    result = []\n",
    "    for train_idx, test_idx in kf.split(range(X.shape[0])):\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        model = torch.nn.Sequential(torch.nn.Linear(9,15),\n",
    "                                 torch.nn.Sigmoid(), \n",
    "\n",
    "                                 torch.nn.Linear(15,1),\n",
    "                                 torch.nn.Sigmoid())\n",
    "\n",
    "        loss = torch.nn.MSELoss(reduce = False)\n",
    "\n",
    "        optimizer=torch.optim.SGD(model.parameters(),lr=0.05,weight_decay=0.001)\n",
    "\n",
    "        sw = y_train.clone()\n",
    "\n",
    "        sw[sw == 1] = y_train.shape[0]/(2*y_train.float().sum())   \n",
    "\n",
    "        sw[sw == 0] = y_train.shape[0]/(2*(y_train==0).float().sum())\n",
    "\n",
    "        for epoch in range(10000):\n",
    "            optimizer.zero_grad()  \n",
    "            out = model(X_train)   \n",
    "            loss1 = (sw * loss(out, y_train)).sum()/sw.sum()   \n",
    "\n",
    "            loss1.backward()     \n",
    "            optimizer.step()     \n",
    "\n",
    "        out_train = model(X_train) \n",
    "        out_test = model(X_test)\n",
    "\n",
    "        acc_train = ((out_train>0.5).float()==y_train).float().mean()\n",
    "        acc_test = ((out_test>0.5).float()==y_test).float().mean()\n",
    "\n",
    "        sen_train =  ((out_train >0.5).float() == y_train)[y_train == 1].float().mean()\n",
    "        sen_test =  ((out_test >0.5).float() == y_test)[y_test == 1].float().mean()\n",
    "\n",
    "        spe_train =  ((out_train >0.5).float() == y_train)[y_train == 0].float().mean()\n",
    "        spe_test =  ((out_test >0.5).float() == y_test)[y_test == 0].float().mean()\n",
    "\n",
    "        train_fpr, train_tpr, train_thresholds = roc_curve(y_train.detach().numpy(), out_train.detach().numpy())\n",
    "        test_fpr, test_tpr, test_thresholds = roc_curve(y_test.detach().numpy(), out_test.detach().numpy())\n",
    "        train_auc = auc(train_fpr, train_tpr)\n",
    "        test_auc = auc(test_fpr, test_tpr)\n",
    "\n",
    "        train_pre = ((out_train>0.5)&(y_train == 1)).sum().numpy()/(out_train >0.5).sum().numpy()\n",
    "        test_pre = ((out_test>0.5)&(y_test == 1)).sum().numpy()/(out_test>0.5).sum().numpy()\n",
    "\n",
    "        F1_train = (2*train_pre*sen_train)/(train_pre + sen_train)\n",
    "        F1_test = (2*test_pre*sen_test)/(test_pre + sen_test)\n",
    "\n",
    "\n",
    "        result.append({'train':{'acc':acc_train, 'sensitivity':sen_train, 'specivity':spe_train,'auc':train_auc, 'F1':F1_train},\n",
    "                       'test':{'acc':acc_test, 'sensitivity':sen_test, 'specivity':spe_test,'auc':test_auc, 'F1':F1_test}})\n",
    "\n",
    "    acc_train, acc_test, sen_train, sen_test, spe_train, spe_test, auc_train, auc_test,F1_train, F1_test = 0,0,0,0,0,0,0,0,0,0\n",
    "    for temp in result:\n",
    "        a =  temp['train']\n",
    "        b = temp ['test']\n",
    "\n",
    "        acc_train += 0.1*a['acc']\n",
    "        acc_test += 0.1*b['acc']\n",
    "        sen_train += 0.1*a['sensitivity']\n",
    "        sen_test += 0.1*b['sensitivity']\n",
    "        spe_train += 0.1*a['specivity']\n",
    "        spe_test += 0.1*b['specivity']\n",
    "        auc_train += 0.1*a['auc']\n",
    "        auc_test += 0.1*b['auc']\n",
    "        F1_train += 0.1*a['F1']\n",
    "        F1_test += 0.1 * b['F1']\n",
    "\n",
    "    out_ex = model(X_ex)\n",
    "    print(len(out_ex))\n",
    "    acc_ex = ((out_ex>0.5).float()==y_ex).float().mean()\n",
    "    sen_ex =  ((out_ex >0.5).float() == y_ex)[y_ex == 1].float().mean()\n",
    "    spe_ex =  ((out_ex >0.5).float() == y_ex)[y_ex == 0].float().mean()\n",
    "\n",
    "    test_fpr, test_tpr, test_thresholds = roc_curve(y_ex.detach().numpy(), out_ex.detach().numpy())\n",
    "    auc_ex = auc(test_fpr, test_tpr)\n",
    "    test_pre = ((out_ex>0.5)&(y_ex == 1)).sum().numpy()/(out_ex>0.5).sum().numpy()\n",
    "\n",
    "    F1_ex = (2*test_pre*sen_test)/(test_pre + sen_test)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ANN_model.ipynb",
   "provenance": [
    {
     "file_id": "1eHt2gBDCmW5GanOHgtcxLvU_EMrnggNx",
     "timestamp": 1608626494569
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
