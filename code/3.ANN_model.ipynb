{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3.ANN_model.ipynb","provenance":[{"file_id":"1eHt2gBDCmW5GanOHgtcxLvU_EMrnggNx","timestamp":1608626494569}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyizrCXmtYc1","executionInfo":{"status":"ok","timestamp":1608903312919,"user_tz":-480,"elapsed":66900,"user":{"displayName":"Tang Tsai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64","userId":"14641643808163269187"}},"outputId":"89700be2-2a2f-48bf-e69a-06dc1b3ff806"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d4Cp67lDbGNw"},"source":["## ANN"]},{"cell_type":"code","metadata":{"id":"IhIDRaN5bGNw","executionInfo":{"status":"ok","timestamp":1608903317276,"user_tz":-480,"elapsed":2337,"user":{"displayName":"Tang Tsai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64","userId":"14641643808163269187"}}},"source":["import sys\n","import os\n","\n","import pandas as pd\n","import numpy as np\n","from scipy import stats\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.metrics import auc, roc_curve\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import svm\n","from sklearn import ensemble\n","from scipy.spatial.distance import pdist, squareform\n","from sklearn.model_selection import cross_val_score, ShuffleSplit\n","\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","matplotlib.rcParams['font.sans-serif'] = ['FangSong']\n","matplotlib.rcParams['axes.unicode_minus'] = False \n","stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LIQy13slLw-G"},"source":["### ANN without 1h/h average SBP & DBP"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_QF1-zw62vmE","executionInfo":{"status":"ok","timestamp":1608903417251,"user_tz":-480,"elapsed":85849,"user":{"displayName":"Tang Tsai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64","userId":"14641643808163269187"}},"outputId":"c1f20f60-702a-4563-f434-238722ca7dae"},"source":["import torch\n","data_range_pro = pd.read_csv('/content/drive/My Drive/hypertension test/Nocturnal_hypertension by C/data_10factors_gbk_dayBP_201222.csv', encoding = 'gbk', index_col = 0)\n","def preprocess(data0):\n","    data = data0.copy()\n","    X_col = [col for col in data.columns if col != 'nocturnal_hypertension']\n","    dummy_col = [col for col in X_col if len(data[col].unique()) < 5]\n","    data[dummy_col] = data[dummy_col].astype('int64')\n","    float_col = [col for col in X_col if col not in dummy_col]\n","    # standard\n","    m,s = data[float_col].mean(), data[float_col].std()\n","    for col in float_col:\n","        data[col] = (data[col] - data[col].mean()) / (data[col].std())\n","    temp = pd.DataFrame()\n","    for col in dummy_col:\n","        temp = pd.concat([temp, pd.get_dummies(data[col], prefix = col, prefix_sep = '_', drop_first = True)], axis = 1)\n","\n","    temp = pd.concat([data[float_col], temp, data['nocturnal_hypertension']], axis = 1)\n","    temp.index = pd.Index(range(len(temp)))\n","    return temp, m, s, float_col, dummy_col, X_col, 'nocturnal_hypertension'\n","\n","data, m, s, float_col, dummy_col, X_col, y_col = preprocess(data_range_pro)\n","data['nocturnal_hypertension'] = data['nocturnal_hypertension'].astype('int')#bool转换成int\n","\n","R = 115306\n","\n","temp = ['Clinic SBP,mmHg','eGFR,mL/ (min·1.73 m2)','BUN,mmol/L','Clinic DBP,mmHg'\n","             ,'nRAAS drugs intake_1', 'Hypertension_1','Age,y'] + [y_col]\n","\n","data_tensor = torch.from_numpy(data[temp].values).float()\n","\n","X = data_tensor[:,:-1]\n","y = data_tensor[:,-1].resize(3103,1)\n","\n","kf = KFold(10,shuffle = True, random_state = R)\n","\n","result = []\n","for train_idx, test_idx in kf.split(range(X.shape[0])):\n","    X_train, X_test = X[train_idx], X[test_idx]\n","    y_train, y_test = y[train_idx], y[test_idx]\n","    model = torch.nn.Sequential(torch.nn.Linear(7,15),\n","                            torch.nn.Sigmoid(), \n","                            torch.nn.Linear(15,1),\n","                            torch.nn.Sigmoid())\n","    loss = torch.nn.MSELoss(reduce = False)\n","    optimizer=torch.optim.SGD(model.parameters(),lr=0.05,weight_decay=0.001)\n","    sw = y_train.clone()\n","\n","    sw[sw == 1] = y_train.shape[0]/(2*y_train.float().sum())   \n","    \n","    sw[sw == 0] = y_train.shape[0]/(2*(y_train==0).float().sum())\n","    \n","    for epoch in range(10000):\n","        optimizer.zero_grad()  \n","        out = model(X_train)  \n","        loss1 = (sw * loss(out, y_train)).sum()/sw.sum()  \n","        loss1.backward()    \n","        optimizer.step()    \n","    out_train = model(X_train) \n","    out_test = model(X_test)\n","\n","    acc_train = ((out_train>0.5).float()==y_train).float().mean()\n","    acc_test = ((out_test>0.5).float()==y_test).float().mean()\n","    sen_train =  ((out_train >0.5).float() == y_train)[y_train == 1].float().mean()\n","    sen_test =  ((out_test >0.5).float() == y_test)[y_test == 1].float().mean()\n","    spe_train =  ((out_train >0.5).float() == y_train)[y_train == 0].float().mean()\n","    spe_test =  ((out_test >0.5).float() == y_test)[y_test == 0].float().mean()\n","\n","    train_fpr, train_tpr, train_thresholds = roc_curve(y_train.detach().numpy(), out_train.detach().numpy())\n","    test_fpr, test_tpr, test_thresholds = roc_curve(y_test.detach().numpy(), out_test.detach().numpy())\n","    train_auc = auc(train_fpr, train_tpr)\n","    test_auc = auc(test_fpr, test_tpr)\n","\n","    train_pre = ((out_train>0.5)&(y_train == 1)).sum().numpy()/(out_train >0.5).sum().numpy()\n","    test_pre = ((out_test>0.5)&(y_test == 1)).sum().numpy()/(out_test>0.5).sum().numpy()\n","\n","    F1_train = (2*train_pre*sen_train)/(train_pre + sen_train)\n","    F1_test = (2*test_pre*sen_test)/(test_pre + sen_test)\n","\n","    result.append({'train':{'acc':acc_train, 'sensitivity':sen_train, 'specivity':spe_train,'auc':train_auc, 'F1':F1_train},\n","                  'test':{'acc':acc_test, 'sensitivity':sen_test, 'specivity':spe_test,'auc':test_auc, 'F1':F1_test}})\n","acc_train, acc_test, sen_train, sen_test, spe_train, spe_test, auc_train, auc_test,F1_train, F1_test = 0,0,0,0,0,0,0,0,0,0\n","for temp in result:\n","    a =  temp['train']\n","    b = temp ['test']\n","    acc_train += 0.1*a['acc']\n","    acc_test += 0.1*b['acc']\n","    sen_train += 0.1*a['sensitivity']\n","    sen_test += 0.1*b['sensitivity']\n","    spe_train += 0.1*a['specivity']\n","    spe_test += 0.1*b['specivity']\n","    auc_train += 0.1*a['auc']\n","    auc_test += 0.1*b['auc']\n","    F1_train += 0.1*a['F1']\n","    F1_test += 0.1 * b['F1']\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n","  warnings.warn(\"non-inplace resize is deprecated\")\n","/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"sdho8pYpMgUz"},"source":["### ANN with 1h/h average SBP & DBP "]},{"cell_type":"code","metadata":{"id":"iz5ooPC5Lo_w","executionInfo":{"status":"ok","timestamp":1608903417264,"user_tz":-480,"elapsed":24252,"user":{"displayName":"Tang Tsai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64","userId":"14641643808163269187"}}},"source":["data_range_pro = pd.read_csv('/content/drive/My Drive/hypertension test/Nocturnal_hypertension by C/data_10factors_gbk_dayBP_201222.csv', encoding = 'gbk', index_col = 0)\n","X_daytime = ['8-9SBP',\n"," '8-9DBP',\n"," '9-10SBP',\n"," '9-10DBP',\n"," '10-11SBP',\n"," '10-11DBP',\n"," '11-12SBP',\n"," '11-12DBP',\n"," '3-4SBP',\n"," '3-4DBP',\n"," '4-5SBP',\n"," '4-5DBP',\n"," '5-6SBP',\n"," '5-6DBP',\n","         \n","  '8-10SBP',\n","  '8-10DBP',\n","  '9-11SBP',\n","  '9-11DBP',\n","  '10-12SBP',\n","  '10-12DBP',\n","  '3-5SBP',\n","  '3-5DBP',\n","  '4-6SBP',\n","  '4-6DBP',\n","]            "],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"dcgnskyssxHT","executionInfo":{"status":"ok","timestamp":1608903417267,"user_tz":-480,"elapsed":22995,"user":{"displayName":"Tang Tsai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64","userId":"14641643808163269187"}}},"source":["df = pd.DataFrame( columns=('8-9SBP',\n","#  '8-9DBP',\n"," '9-10SBP',\n","#  '9-10DBP',\n"," '10-11SBP',\n","#  '10-11DBP',\n"," '11-12SBP',\n","#  '11-12DBP',\n"," '3-4SBP',\n","#  '3-4DBP',\n"," '4-5SBP',\n","#  '4-5DBP',\n"," '5-6SBP',\n","#  '5-6DBP',\n","         \n","  '8-10SBP',\n","#  '8-10DBP',\n","  '9-11SBP',\n","#  '9-11DBP',\n","  '10-12SBP',\n","#  '10-12DBP',\n","  '3-5SBP',\n","#  '3-5DBP',\n","  '4-6SBP',\n","#  '4-6DBP',\n","))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t92LWF_zbGN1","scrolled":false,"executionInfo":{"status":"ok","timestamp":1608904399805,"user_tz":-480,"elapsed":1003854,"user":{"displayName":"Tang Tsai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64","userId":"14641643808163269187"}},"outputId":"a8178dae-21ea-48cf-c317-8020e244fc39"},"source":["import torch\n","data_range_pro = pd.read_csv('/content/drive/My Drive/hypertension test/Nocturnal_hypertension by C/data_10factors_gbk_dayBP_201222.csv', encoding = 'gbk', index_col = 0)\n","def preprocess(data0):\n","    data = data0.copy()\n","    X_col = [col for col in data.columns if col != 'nocturnal_hypertension']\n","    dummy_col = [col for col in X_col if len(data[col].unique()) < 5]\n","    data[dummy_col] = data[dummy_col].astype('int64')\n","    float_col = [col for col in X_col if col not in dummy_col]\n","    # standard\n","    m,s = data[float_col].mean(), data[float_col].std()\n","    for col in float_col:\n","        data[col] = (data[col] - data[col].mean()) / (data[col].std())\n","    temp = pd.DataFrame()\n","    for col in dummy_col:\n","        temp = pd.concat([temp, pd.get_dummies(data[col], prefix = col, prefix_sep = '_', drop_first = True)], axis = 1)\n","\n","    temp = pd.concat([data[float_col], temp, data['nocturnal_hypertension']], axis = 1)\n","    temp.index = pd.Index(range(len(temp)))\n","    return temp, m, s, float_col, dummy_col, X_col, 'nocturnal_hypertension'\n","\n","data, m, s, float_col, dummy_col, X_col, y_col = preprocess(data_range_pro)\n","data['nocturnal_hypertension'] = data['nocturnal_hypertension'].astype('int')#bool转换成int\n","\n","R = 115306\n","\n","temp = ['Clinic SBP,mmHg','eGFR,mL/ (min·1.73 m2)','BUN,mmol/L','Clinic DBP,mmHg'\n","             ,'nRAAS drugs intake_1', 'Hypertension_1','Age,y'] + [y_col]\n","\n","for j in range(int(len(X_daytime)/2)):\n","    i = j*2\n","    temp = ['Clinic SBP,mmHg','eGFR,mL/ (min·1.73 m2)','BUN,mmol/L','Clinic DBP,mmHg'\n","             ,'nRAAS drugs intake_1', 'Hypertension_1','Age,y',\n","      X_daytime[i],X_daytime[i+1]\n","    ] + [y_col]\n","    data_tensor = torch.from_numpy(data[temp].values).float()\n","\n","    X = data_tensor[:,:-1]\n","    y = data_tensor[:,-1].resize(3103,1)\n","\n","    kf = KFold(10,shuffle = True, random_state = R)\n","\n","    result = []\n","    for train_idx, test_idx in kf.split(range(X.shape[0])):\n","        X_train, X_test = X[train_idx], X[test_idx]\n","        y_train, y_test = y[train_idx], y[test_idx]\n","        model = torch.nn.Sequential(torch.nn.Linear(9,15),\n","                                torch.nn.Sigmoid(), \n","                                torch.nn.Linear(15,1),\n","                                torch.nn.Sigmoid())\n","        loss = torch.nn.MSELoss(reduce = False)\n","        optimizer=torch.optim.SGD(model.parameters(),lr=0.05,weight_decay=0.001)\n","        sw = y_train.clone()\n","\n","        sw[sw == 1] = y_train.shape[0]/(2*y_train.float().sum())   \n","        \n","        sw[sw == 0] = y_train.shape[0]/(2*(y_train==0).float().sum())\n","        \n","        for epoch in range(10000):\n","            optimizer.zero_grad()  \n","            out = model(X_train)  \n","            loss1 = (sw * loss(out, y_train)).sum()/sw.sum()  \n","            loss1.backward()    \n","            optimizer.step()    \n","        out_train = model(X_train) \n","        out_test = model(X_test)\n","\n","        acc_train = ((out_train>0.5).float()==y_train).float().mean()\n","        acc_test = ((out_test>0.5).float()==y_test).float().mean()\n","        sen_train =  ((out_train >0.5).float() == y_train)[y_train == 1].float().mean()\n","        sen_test =  ((out_test >0.5).float() == y_test)[y_test == 1].float().mean()\n","        spe_train =  ((out_train >0.5).float() == y_train)[y_train == 0].float().mean()\n","        spe_test =  ((out_test >0.5).float() == y_test)[y_test == 0].float().mean()\n","\n","        train_fpr, train_tpr, train_thresholds = roc_curve(y_train.detach().numpy(), out_train.detach().numpy())\n","        test_fpr, test_tpr, test_thresholds = roc_curve(y_test.detach().numpy(), out_test.detach().numpy())\n","        train_auc = auc(train_fpr, train_tpr)\n","        test_auc = auc(test_fpr, test_tpr)\n","\n","        train_pre = ((out_train>0.5)&(y_train == 1)).sum().numpy()/(out_train >0.5).sum().numpy()\n","        test_pre = ((out_test>0.5)&(y_test == 1)).sum().numpy()/(out_test>0.5).sum().numpy()\n","\n","        F1_train = (2*train_pre*sen_train)/(train_pre + sen_train)\n","        F1_test = (2*test_pre*sen_test)/(test_pre + sen_test)\n","\n","        result.append({'train':{'acc':acc_train, 'sensitivity':sen_train, 'specivity':spe_train,'auc':train_auc, 'F1':F1_train},\n","                      'test':{'acc':acc_test, 'sensitivity':sen_test, 'specivity':spe_test,'auc':test_auc, 'F1':F1_test}})\n","    acc_train, acc_test, sen_train, sen_test, spe_train, spe_test, auc_train, auc_test,F1_train, F1_test = 0,0,0,0,0,0,0,0,0,0\n","    for temp in result:\n","        a =  temp['train']\n","        b = temp ['test']\n","        acc_train += 0.1*a['acc']\n","        acc_test += 0.1*b['acc']\n","        sen_train += 0.1*a['sensitivity']\n","        sen_test += 0.1*b['sensitivity']\n","        spe_train += 0.1*a['specivity']\n","        spe_test += 0.1*b['specivity']\n","        auc_train += 0.1*a['auc']\n","        auc_test += 0.1*b['auc']\n","        F1_train += 0.1*a['F1']\n","        F1_test += 0.1 * b['F1']"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n","  warnings.warn(\"non-inplace resize is deprecated\")\n","/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"tpgL18h9KRJM"},"source":["### **Test with extra data**"]},{"cell_type":"code","metadata":{"id":"hbXTyRRJJo01","executionInfo":{"status":"ok","timestamp":1608904709132,"user_tz":-480,"elapsed":1729,"user":{"displayName":"Tang Tsai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64","userId":"14641643808163269187"}}},"source":["data_range_pro = pd.read_csv('/content/drive/My Drive/hypertension test/Nocturnal_hypertension by C/data_10factors_gbk_dayBP_201222.csv', encoding = 'gbk', index_col = 0)\n","data_ex_valid = pd.read_csv('/content/drive/My Drive/hypertension test/Nocturnal_hypertension by C/data_ex_valid_new.csv', encoding= 'gbk', index_col =0)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"9g33hotLJxZK","executionInfo":{"status":"ok","timestamp":1608904718846,"user_tz":-480,"elapsed":2083,"user":{"displayName":"Tang Tsai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64","userId":"14641643808163269187"}}},"source":["X_daytime = ['8-9SBP',\n"," '8-9DBP',\n"," '9-10SBP',\n"," '9-10DBP',\n"," '10-11SBP',\n"," '10-11DBP',\n"," '11-12SBP',\n"," '11-12DBP',\n"," '3-4SBP',\n"," '3-4DBP',\n"," '4-5SBP',\n"," '4-5DBP',\n"," '5-6SBP',\n"," '5-6DBP',\n","         \n","  '8-10SBP',\n","  '8-10DBP',\n","  '9-11SBP',\n","  '9-11DBP',\n","  '10-12SBP',\n","  '10-12DBP',\n","  '3-5SBP',\n","  '3-5DBP',\n","  '4-6SBP',\n","  '4-6DBP',\n","]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9SfBH7BFhwm","executionInfo":{"status":"ok","timestamp":1608905739657,"user_tz":-480,"elapsed":998733,"user":{"displayName":"Tang Tsai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitAyzgeaxnlOCWsfNpzaNnAdBUoDyTsY8wFnvs=s64","userId":"14641643808163269187"}},"outputId":"196861cd-957b-4812-aec6-d41332d1cbae"},"source":["data, m, s, float_col, dummy_col, X_col, y_col = preprocess(data_range_pro)\n","data['nocturnal_hypertension'] = data['nocturnal_hypertension'].astype('int')\n","data_ex, m_ex, s_ex, float_col_ex, dummy_col_ex, X_col_ex, y_col_ex = preprocess(data_ex_valid)\n","data_ex['nocturnal_hypertension'] = data_ex['nocturnal_hypertension'].astype('int')                                                                                \n","\n","for j in range(int(len(X_daytime)/2)):\n","    i = j*2\n","    temp = ['Clinic SBP,mmHg','eGFR,mL/ (min·1.73 m2)','BUN,mmol/L','Clinic DBP,mmHg'\n","             ,'nRAAS drugs intake_1', 'Hypertension_1','Age,y',\n","      X_daytime[i],X_daytime[i+1]\n","    ] + [y_col]\n","\n","    data_tensor = torch.from_numpy(data[temp].values).float()\n","    data_tensor_ex = torch.from_numpy(data_ex[temp].values).float()\n","\n","    X = data_tensor[:,:-1]\n","    y = data_tensor[:,-1].resize(3103,1)\n","\n","    X_ex = data_tensor_ex[:,:-1]\n","    y_ex = data_tensor_ex[:,-1].resize(229,1)\n","\n","    kf = KFold(10,shuffle = True, random_state = 115306)\n","\n","    result = []\n","    for train_idx, test_idx in kf.split(range(X.shape[0])):\n","\n","        X_train, X_test = X[train_idx], X[test_idx]\n","        y_train, y_test = y[train_idx], y[test_idx]\n","        model = torch.nn.Sequential(torch.nn.Linear(9,15),\n","                                 torch.nn.Sigmoid(), \n","\n","                                 torch.nn.Linear(15,1),\n","                                 torch.nn.Sigmoid())\n","\n","        loss = torch.nn.MSELoss(reduce = False)\n","\n","        optimizer=torch.optim.SGD(model.parameters(),lr=0.05,weight_decay=0.001)\n","\n","        sw = y_train.clone()\n","\n","        sw[sw == 1] = y_train.shape[0]/(2*y_train.float().sum())   \n","\n","        sw[sw == 0] = y_train.shape[0]/(2*(y_train==0).float().sum())\n","\n","        for epoch in range(10000):\n","            optimizer.zero_grad()  \n","            out = model(X_train)   \n","            loss1 = (sw * loss(out, y_train)).sum()/sw.sum()   \n","\n","            loss1.backward()     \n","            optimizer.step()     \n","\n","        out_train = model(X_train) \n","        out_test = model(X_test)\n","\n","        acc_train = ((out_train>0.5).float()==y_train).float().mean()\n","        acc_test = ((out_test>0.5).float()==y_test).float().mean()\n","\n","        sen_train =  ((out_train >0.5).float() == y_train)[y_train == 1].float().mean()\n","        sen_test =  ((out_test >0.5).float() == y_test)[y_test == 1].float().mean()\n","\n","        spe_train =  ((out_train >0.5).float() == y_train)[y_train == 0].float().mean()\n","        spe_test =  ((out_test >0.5).float() == y_test)[y_test == 0].float().mean()\n","\n","        train_fpr, train_tpr, train_thresholds = roc_curve(y_train.detach().numpy(), out_train.detach().numpy())\n","        test_fpr, test_tpr, test_thresholds = roc_curve(y_test.detach().numpy(), out_test.detach().numpy())\n","        train_auc = auc(train_fpr, train_tpr)\n","        test_auc = auc(test_fpr, test_tpr)\n","\n","        train_pre = ((out_train>0.5)&(y_train == 1)).sum().numpy()/(out_train >0.5).sum().numpy()\n","        test_pre = ((out_test>0.5)&(y_test == 1)).sum().numpy()/(out_test>0.5).sum().numpy()\n","\n","        F1_train = (2*train_pre*sen_train)/(train_pre + sen_train)\n","        F1_test = (2*test_pre*sen_test)/(test_pre + sen_test)\n","\n","\n","        result.append({'train':{'acc':acc_train, 'sensitivity':sen_train, 'specivity':spe_train,'auc':train_auc, 'F1':F1_train},\n","                       'test':{'acc':acc_test, 'sensitivity':sen_test, 'specivity':spe_test,'auc':test_auc, 'F1':F1_test}})\n","\n","    acc_train, acc_test, sen_train, sen_test, spe_train, spe_test, auc_train, auc_test,F1_train, F1_test = 0,0,0,0,0,0,0,0,0,0\n","    for temp in result:\n","        a =  temp['train']\n","        b = temp ['test']\n","\n","        acc_train += 0.1*a['acc']\n","        acc_test += 0.1*b['acc']\n","        sen_train += 0.1*a['sensitivity']\n","        sen_test += 0.1*b['sensitivity']\n","        spe_train += 0.1*a['specivity']\n","        spe_test += 0.1*b['specivity']\n","        auc_train += 0.1*a['auc']\n","        auc_test += 0.1*b['auc']\n","        F1_train += 0.1*a['F1']\n","        F1_test += 0.1 * b['F1']\n","\n","    out_ex = model(X_ex)\n","    # print(len(out_ex))\n","    acc_ex = ((out_ex>0.5).float()==y_ex).float().mean()\n","    sen_ex =  ((out_ex >0.5).float() == y_ex)[y_ex == 1].float().mean()\n","    spe_ex =  ((out_ex >0.5).float() == y_ex)[y_ex == 0].float().mean()\n","\n","    test_fpr, test_tpr, test_thresholds = roc_curve(y_ex.detach().numpy(), out_ex.detach().numpy())\n","    auc_ex = auc(test_fpr, test_tpr)\n","    test_pre = ((out_ex>0.5)&(y_ex == 1)).sum().numpy()/(out_ex>0.5).sum().numpy()\n","\n","    F1_ex = (2*test_pre*sen_test)/(test_pre + sen_test)\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n","  warnings.warn(\"non-inplace resize is deprecated\")\n","/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"}]}]}